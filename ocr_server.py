from flask import Flask, request, jsonify
from flask_cors import CORS
from bs4 import BeautifulSoup
import urllib.parse
import os
import time
import re
import requests
import tempfile

app = Flask(__name__)
CORS(app, origins=['*'])

class ModelToTMMapper:
    """Ê®°ÂûãÂè∑Âà∞TMÂè∑ÁöÑÊò†Â∞ÑÊï∞ÊçÆÂ∫ì"""
    
    def __init__(self):
        # ÂèëÁîµÊú∫Ê®°ÂûãÊò†Â∞ÑÊï∞ÊçÆÂ∫ì
        self.generator_mappings = {
            'MEP-1030A': ['9-6115-749-10'],
            'MEP-1031': ['9-6115-749-10'],
            'MEP-802A': ['9-6115-641-10'],
            'MEP-803A': ['9-6115-642-10'],
            'MEP-804A': ['9-6115-643-10'],
            'MEP-804B': ['9-6115-643-10'],
            'MEP-805A': ['9-6115-644-10'],
            'MEP-806A': ['9-6115-645-10'],
            'MEP-806B': ['9-6115-672-14'],
            'MEP-812A': ['9-6115-641-10'],
            'MEP-813A': ['9-6115-642-10'],
            'MEP-814A': ['9-6115-643-10'],
            'MEP-814B': ['9-6115-643-10'],
            'MEP-815A': ['9-6115-644-10'],
            'MEP-816A': ['9-6115-645-10'],
            'MEP-816B': ['9-6115-672-14'],
            'MEP-952B': ['9-6115-664-13'],
            'MEP-831A': ['9-6115-639-13'],
            'MEP-832A': ['9-6115-639-13'],
            'MEP-003A': ['9-6115-585-24P'],
            'MEP-112A': ['9-6115-585-24P'],
            'MEP-113A': ['9-6115-464-34'],
            'MEP-004A': ['9-6115-464-34'],
            'MEP-103A': ['9-6115-464-34'],
        }
        
        # ÈÄö‰ø°ËÆæÂ§áÊò†Â∞Ñ
        self.comm_mappings = {
            'AN/PRC-119': ['11-5820-890-10-3'],
            'AN/VRC-87': ['11-5820-890-10-3'],
            'AN/VRC-88': ['11-5820-890-10-3'],
            'AN/PRC-127': ['11-5820-1048-24'],
        }
        
        # ËΩ¶ËæÜÊò†Â∞Ñ
        self.vehicle_mappings = {
            'M1151': ['9-2320-387-10'],
            'M1152': ['9-2320-387-10'],
            'M1165': ['9-2320-387-10'],
            'HMMWV': ['9-2320-280-10', '9-2320-280-20'],
            'M998': ['9-2320-280-10'],
            'M1025': ['9-2320-280-10'],
            'M1043': ['9-2320-280-10'],
            'M200A/P': ['9-6150-226-13', '9-6150-226-23P'],
            'M200A': ['9-6150-226-13', '9-6150-226-23P'],
            'M200AP': ['9-6150-226-13', '9-6150-226-23P'],
        }
        
        # ÂêàÂπ∂ÊâÄÊúâÊò†Â∞Ñ
        self.all_mappings = {}
        self.all_mappings.update(self.generator_mappings)
        self.all_mappings.update(self.comm_mappings)
        self.all_mappings.update(self.vehicle_mappings)

    def find_tm_numbers_for_model(self, model_number):
        """Ê†πÊçÆÊ®°ÂûãÂè∑Êü•ÊâæÂØπÂ∫îÁöÑTMÂè∑"""
        if not model_number:
            return []
        
        print(f"üîç Looking for TM numbers for model: '{model_number}'")
        
        # Ê∏ÖÁêÜÊ®°ÂûãÂè∑
        clean_model = self.normalize_model_number(model_number)
        print(f"üîé Normalized model: '{clean_model}'")
        
        # Áõ¥Êé•ÂåπÈÖç
        if clean_model in self.all_mappings:
            result = self.all_mappings[clean_model]
            print(f"‚úÖ Direct match found: {clean_model} ‚Üí {result}")
            return result
        
        # Ê®°Á≥äÂåπÈÖç
        fuzzy_matches = []
        for mapped_model, tm_list in self.all_mappings.items():
            # ÁßªÈô§ËøûÂ≠óÁ¨¶ÊØîËæÉ
            if clean_model.replace('-', '').replace('_', '') == mapped_model.replace('-', '').replace('_', ''):
                fuzzy_matches.extend(tm_list)
                print(f"‚úÖ Fuzzy match found: {clean_model} ‚âà {mapped_model} ‚Üí {tm_list}")
            # ÈÉ®ÂàÜÂåπÈÖç
            elif clean_model in mapped_model or mapped_model in clean_model:
                fuzzy_matches.extend(tm_list)
                print(f"‚úÖ Partial match found: {clean_model} ‚Üî {mapped_model} ‚Üí {tm_list}")
        
        result = list(set(fuzzy_matches))  # ÂéªÈáç
        print(f"üìä Final result: {result}")
        return result

    def normalize_model_number(self, model):
        """Ê†áÂáÜÂåñÊ®°ÂûãÂè∑Ê†ºÂºè"""
        if not model:
            return ''
        
        model = model.upper().strip()
        
        # Â§ÑÁêÜÊñúÊù†Ê†ºÂºè M200A/P
        if 'M200A/P' in model or model == 'M200A/P':
            return 'M200A/P'
        elif model.replace('/', '').replace(' ', '') == 'M200AP':
            return 'M200A/P'
        elif 'M200A' in model:
            return 'M200A/P'
        
        # Ê∑ªÂä†MEPÂâçÁºÄÂ¶ÇÊûúÁº∫Â§±
        if model.startswith(('1030', '1031', '804', '805', '806', '807', '812', '813', '814', '815', '816', '817', '831', '832', '803')):
            if not model.startswith('MEP'):
                model = f'MEP-{model}'
        
        return model

class RealisticManualSearcher:
    def __init__(self):
        self.target_sites = [
            {
                'name': 'Liberated Manuals',
                'domain': 'www.liberatedmanuals.com',
                'priority': 1,
                'methods': [
                    {
                        'type': 'direct_pdf_patterns',
                        'patterns': [
                            'https://www.liberatedmanuals.com/TM-{tm_dashed}.pdf',
                            'https://www.liberatedmanuals.com/TM_{tm_underscore}.pdf',
                            'https://www.liberatedmanuals.com/{tm_dashed}.pdf'
                        ]
                    }
                ]
            },
            {
                'name': 'Green Mountain Generators',
                'domain': 'greenmountaingenerators.com',
                'priority': 2,
                'methods': [
                    {
                        'type': 'direct_and_search',
                        'base_patterns': [
                            'https://greenmountaingenerators.com/wp-content/uploads/2012/10/MEP-003A-Unit-Direct-Support-General-Support-and-Depot-Level-Maintenance-Repair-Parts-and-Special-Tools-List-TM-{tm_dashed}.pdf',
                            'https://greenmountaingenerators.com/wp-content/uploads/{year}/{month}/TM-{tm_dashed}.pdf',
                            'https://greenmountaingenerators.com/manuals/TM-{tm_dashed}.pdf'
                        ],
                        'search_url': 'https://greenmountaingenerators.com/?s={query}'
                    }
                ]
            },
            {
                'name': 'Combat Index',
                'domain': 'combatindex.com',
                'priority': 3,
                'methods': [
                    {
                        'type': 'direct_pdf_patterns',
                        'patterns': [
                            'http://combatindex.com/store/tech_man/Sample/Generators/TM_{tm_underscore}.pdf',
                            'https://combatindex.com/store/tech_man/Sample/Generators/TM_{tm_underscore}.pdf',
                            'http://combatindex.com/store/tech_man/Sample/TM_{tm_underscore}.pdf'
                        ]
                    }
                ]
            },
            {
                'name': 'Radio Nerds',
                'domain': 'radionerds.com',
                'priority': 4,
                'methods': [
                    {
                        'type': 'site_search_only',  # No more hardcoded paths
                        'search_url': 'https://radionerds.com/index.php?search={query}&title=Special:Search&go=Go',
                        'fallback_google': 'site:radionerds.com "{query}" filetype:pdf'
                    }
                ]
            },            
        ]
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Connection': 'keep-alive'
        })
        
        # ÂàùÂßãÂåñÊ®°ÂûãÊò†Â∞ÑÂô®
        self.model_mapper = ModelToTMMapper()

    def format_tm_number(self, tm_number):
        """Ê†ºÂºèÂåñTMÂè∑‰∏∫‰∏çÂêåÁöÑÊ®°ÂºèÔºåÊîØÊåÅ4ÊÆµÂíå5ÊÆµTMÂè∑"""
        if not tm_number:
            return {}
        
        clean_tm = re.sub(r'^TM\s*', '', tm_number.upper(), flags=re.IGNORECASE)
        clean_tm = clean_tm.strip()
        
        formats = {
            'tm_clean': clean_tm.replace('-', '').replace(' ', ''),
            'tm_dashed': clean_tm,
            'tm_underscore': clean_tm.replace('-', '_'),
            'tm_spaced': clean_tm.replace('-', ' '),
            'tm_original': tm_number
        }
        
        # Â§ÑÁêÜTMÂè∑ÁöÑÈÉ®ÂàÜÂåπÈÖçÔºàÂâç‰∏âÊÆµÔºâ
        parts = clean_tm.split('-')
        if len(parts) >= 3:
            # Ââç‰∏âÊÆµÁî®‰∫éÈÉ®ÂàÜÂåπÈÖç
            partial = '-'.join(parts[:3])
            formats.update({
                'tm_partial': partial,
                'tm_partial_clean': partial.replace('-', ''),
                'tm_partial_underscore': partial.replace('-', '_'),
                'tm_partial_pattern': partial + '-'  # Áî®‰∫éÊêúÁ¥¢‰ª•Ê≠§ÂºÄÂ§¥ÁöÑTMÂè∑
            })
        
        # Â¶ÇÊûúÊòØ5ÊÆµTMÂè∑ÔºàÂ¶Ç9-6115-585-24PÔºâÔºå‰πüÊèêÂèñÂâçÂõõÊÆµ
        if len(parts) >= 4:
            partial_four = '-'.join(parts[:4])
            formats.update({
                'tm_partial_four': partial_four,
                'tm_partial_four_underscore': partial_four.replace('-', '_')
            })
        
        return formats    
    
    def extract_tm_from_url(self, url):
        patterns = [
            r'tm[_-]?(\d+[_-]\d+[_-]\d+[_-]\d+[a-z]*)',  # TM-9-6115-585-24P
            r'/(\d+[_-]\d+[_-]\d+[_-]\d+[a-z]*)\.pdf',   # /9-6115-585-24P.pdf
            r'(\d+[_-]\d+[_-]\d+[_-]\d+[a-z]*)',         # Áõ¥Êé•ÂåπÈÖçÊï∞Â≠óÊ®°Âºè
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url.lower())
            if match:
                return match.group(1).replace('_', '-')
        
        return None

    def search_liberated_manuals(self, tm_formats):
        """ÊêúÁ¥¢Liberated Manuals"""
        results = []
        
        print("üìö Searching Liberated Manuals...")
        
        patterns = [
            'https://www.liberatedmanuals.com/TM-{tm_dashed}.pdf',
            'https://www.liberatedmanuals.com/TM_{tm_underscore}.pdf',
            'https://www.liberatedmanuals.com/{tm_dashed}.pdf'
        ]
        
        for pattern in patterns:
            try:
                url = pattern.format(**tm_formats)
                print(f"  üîó Testing: {url}")
                
                response = self.session.head(url, timeout=10, allow_redirects=True)
                if response.status_code == 200:
                    content_type = response.headers.get('content-type', '').lower()
                    if 'pdf' in content_type:
                        results.append({
                            'url': url,
                            'title': f"TM {tm_formats['tm_dashed']} - Liberated Manuals",
                            'confidence': 95,
                            'method': 'direct_pdf',
                            'site': 'Liberated Manuals',
                            'verified': True
                        })
                        print(f"    ‚úÖ Found PDF!")
                        break
                        
            except Exception as e:
                print(f"    ‚ùå Error testing {url}: {e}")
        
        return results

    def search_radio_nerds(self, tm_formats):
        """Hybrid RadioNerds search: try intelligent patterns first, then fallbacks"""
        results = []
        
        print("üìª Searching Radio Nerds (hybrid method)...")
        print("  üîç Trying MediaWiki search...")
        search_queries = [
            tm_formats['tm_dashed'],
            f"TM {tm_formats['tm_dashed']}",
            f"TM-{tm_formats['tm_dashed']}",
            tm_formats['tm_dashed'].replace('-', ' ')
        ]
        
        for query in search_queries:
            try:
                search_url = f"https://radionerds.com/index.php?search={urllib.parse.quote(query)}&title=Special:Search"
                print(f"  üîç MediaWiki search: {search_url}")
                
                response = self.session.get(search_url, timeout=15)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # Look for any links containing our TM number
                    for link in soup.find_all('a', href=True):
                        href = link.get('href', '')
                        link_text = link.get_text().strip()
                        
                        # Êõ¥‰∏•Ê†ºÁöÑÂåπÈÖçÔºöË¶ÅÊ±ÇËá≥Â∞ëÂåπÈÖç3‰∏™ÈÉ®ÂàÜ
                        tm_parts = tm_formats['tm_dashed'].split('-')
                        href_matches = sum(1 for part in tm_parts if part in href.lower())
                        text_matches = sum(1 for part in tm_parts if part in link_text.lower())
                        
                        if href_matches >= 3 or text_matches >= 3:
                            if href.startswith('/'):
                                href = f"https://radionerds.com{href}"
                            elif not href.startswith('http'):
                                continue
                            
                            # If it's a direct PDF link
                            if '.pdf' in href.lower():
                                # ‰ªéPDFÈìæÊé•‰∏≠ÊèêÂèñÂÆûÈôÖÁöÑTMÂè∑
                                actual_tm = self.extract_tm_from_url(pdf_href)
                                if actual_tm:
                                    title = f"TM {actual_tm} - Radio Nerds"
                                else:
                                    actual_tm = tm_formats['tm_dashed']
                                    title = f"TM {actual_tm} - Radio Nerds"
                                
                                try:
                                    head_response = self.session.head(href, timeout=5)
                                    if head_response.status_code == 200:
                                        results.append({
                                            'url': href,
                                            'title': title,  # ‰ΩøÁî®ÊèêÂèñÁöÑÂÆûÈôÖTMÂè∑
                                            'confidence': 90,
                                            'method': 'mediawiki_search',
                                            'site': 'Radio Nerds',
                                            'verified': True,
                                            'actual_tm_found': actual_tm
                                        })
                                        print(f"    Found via MediaWiki search: {href}")
                                        return results
                                except:
                                    continue
                            
                            # If it's a page that might contain PDF links
                            elif 'index.php' in href or 'MEP' in link_text.upper():
                                try:
                                    page_response = self.session.get(href, timeout=10)
                                    if page_response.status_code == 200:
                                        page_soup = BeautifulSoup(page_response.text, 'html.parser')
                                        
                                        # Look for PDF links on this page
                                        for pdf_link in page_soup.find_all('a', href=True):
                                            pdf_href = pdf_link.get('href', '')
                                            if '.pdf' in pdf_href.lower():
                                                # Âú®È°µÈù¢Áà¨Âèñ‰∏≠‰πü‰ΩøÁî®‰∏•Ê†ºÂåπÈÖç
                                                tm_parts = tm_formats['tm_dashed'].split('-')
                                                pdf_matches = sum(1 for part in tm_parts if part in pdf_href.lower())
                                                
                                                if pdf_matches >= 3:  # Ë¶ÅÊ±ÇËá≥Â∞ëÂåπÈÖç3‰∏™ÈÉ®ÂàÜ
                                                    if pdf_href.startswith('/'):
                                                        pdf_href = f"https://radionerds.com{pdf_href}"
                                                    
                                                    # ‰ªéPDFÈìæÊé•‰∏≠ÊèêÂèñÂÆûÈôÖÁöÑTMÂè∑
                                                    actual_tm = self.extract_tm_from_url(pdf_href)
                                                    if actual_tm:
                                                        title = f"TM {actual_tm} - Radio Nerds"
                                                    else:
                                                        actual_tm = tm_formats['tm_dashed']
                                                        title = f"TM {actual_tm} - Radio Nerds"
                                                    
                                                    try:
                                                        pdf_head = self.session.head(pdf_href, timeout=5)
                                                        if pdf_head.status_code == 200:
                                                            results.append({
                                                                'url': pdf_href,
                                                                'title': title,  # ‰ΩøÁî®ÊèêÂèñÁöÑÂÆûÈôÖTMÂè∑
                                                                'confidence': 88,
                                                                'method': 'page_crawl',
                                                                'site': 'Radio Nerds',
                                                                'verified': True,
                                                                'actual_tm_found': actual_tm
                                                            })
                                                            print(f"    ‚úÖ Found via page crawl: {pdf_href}")
                                                            return results
                                                    except:
                                                        continue
                                except:
                                    continue
                
            except Exception as e:
                print(f"    ‚ùå MediaWiki search error: {e}")
        
        return results

    def search_green_mountain(self, tm_formats):
        """ÊêúÁ¥¢Green Mountain Generators - Êî∂ÈõÜÊâÄÊúâÂåπÈÖçÁªìÊûú"""
        results = []
        
        print("ÊêúÁ¥¢Green Mountain Generators...")
        
        manual_pages = [
            'https://greenmountaingenerators.com/manuals-and-support/'
        ]
        
        for page_url in manual_pages:
            try:
                print(f"  Ê£ÄÊü•ÊâãÂÜåÈ°µÈù¢: {page_url}")
                
                response = self.session.get(page_url, timeout=15)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    candidates = []
                    tm_parts = tm_formats['tm_dashed'].split('-')
                    
                    # Êî∂ÈõÜÊâÄÊúâÂåπÈÖçÁöÑÂÄôÈÄâÁªìÊûú
                    for link in soup.find_all('a', href=True):
                        href = link.get('href', '')
                        
                        if href.endswith('.pdf'):
                            import re
                            tm_match = re.search(r'tm[_-]?(\d+)[_-](\d+)[_-](\d+)[_-](\d+[a-z]*)', href.lower())
                            
                            if tm_match:
                                found_parts = [tm_match.group(1), tm_match.group(2), tm_match.group(3), tm_match.group(4)]
                                
                                # Ê£ÄÊü•Ââç3ÊÆµÊòØÂê¶ÂÆåÂÖ®ÂåπÈÖç
                                first_three_match = (tm_parts[0] == found_parts[0] and 
                                                  tm_parts[1] == found_parts[1] and 
                                                  tm_parts[2] == found_parts[2])
                                
                                # Ê£ÄÊü•ÊâÄÊúâ4ÊÆµÊòØÂê¶ÂÆåÂÖ®ÂåπÈÖç
                                all_match = (len(tm_parts) >= 4 and 
                                          tm_parts[0] == found_parts[0] and 
                                          tm_parts[1] == found_parts[1] and 
                                          tm_parts[2] == found_parts[2] and 
                                          tm_parts[3] == found_parts[3])
                                
                                if all_match:
                                    actual_tm = '-'.join(found_parts)
                                    candidates.append({
                                        'url': href,
                                        'actual_tm': actual_tm,
                                        'match_type': 'exact',
                                        'confidence': 95
                                    })
                                    print(f"    ÊâæÂà∞Á≤æÁ°ÆÂåπÈÖç: {actual_tm}")
                                elif first_three_match:
                                    actual_tm = '-'.join(found_parts)
                                    candidates.append({
                                        'url': href,
                                        'actual_tm': actual_tm,
                                        'match_type': 'partial',
                                        'confidence': 85
                                    })
                                    print(f"    ÊâæÂà∞ÈÉ®ÂàÜÂåπÈÖç: {actual_tm}")
                    
                    # ÈÄâÊã©ÊúÄ‰Ω≥ÂåπÈÖçÁªìÊûú
                    if candidates:
                        # ‰ºòÂÖàÁ≤æÁ°ÆÂåπÈÖçÔºåÁÑ∂ÂêéÊòØÈÉ®ÂàÜÂåπÈÖç
                        exact_matches = [c for c in candidates if c['match_type'] == 'exact']
                        partial_matches = [c for c in candidates if c['match_type'] == 'partial']
                        
                        all_matches = exact_matches + partial_matches
                        
                        for match in all_matches[:3]:  # ÊúÄÂ§öËøîÂõû3‰∏™ÁªìÊûú
                            title_suffix = "" if match['match_type'] == 'exact' else f"Partial match for {tm_formats['tm_dashed']}"
                            
                            results.append({
                                'url': match['url'],
                                'title': f"TM {match['actual_tm']}",
                                'title_suffix': title_suffix,
                                'confidence': match['confidence'],
                                'method': 'manual_page_crawl',
                                'site': 'Green Mountain Generators',
                                'verified': False,
                                'actual_tm_found': match['actual_tm']
                            })
                        
                        return results
                            
            except Exception as e:
                print(f"    Ê£ÄÊü•{page_url}Êó∂Âá∫Èîô: {e}")
                continue
        
        return results

    def search_combat_index(self, tm_formats):
        """ÊêúÁ¥¢Combat Index"""
        results = []
        
        print("‚öîÔ∏è Searching Combat Index...")
        
        patterns = [
            'http://combatindex.com/store/tech_man/Sample/Generators/TM_{tm_underscore}.pdf',
            'http://combatindex.com/store/tech_man/Sample/Generators/TM_{tm_dashed}.pdf',
            'https://combatindex.com/store/tech_man/Sample/Generators/TM_{tm_underscore}.pdf',
            'https://combatindex.com/store/tech_man/Sample/Generators/TM_{tm_dashed}.pdf',
            'http://combatindex.com/store/tech_man/Sample/TM_{tm_underscore}.pdf'
        ]
        
        for pattern in patterns:
            try:
                url = pattern.format(**tm_formats)
                print(f"  üîó Testing: {url}")
                
                response = self.session.head(url, timeout=10, allow_redirects=True)
                if response.status_code == 200:
                    content_type = response.headers.get('content-type', '').lower()
                    if 'pdf' in content_type:
                        results.append({
                            'url': url,
                            'title': f"TM {tm_formats['tm_dashed']} - Combat Index",
                            'confidence': 90,
                            'method': 'direct_pdf',
                            'site': 'Combat Index',
                            'verified': True
                        })
                        print(f"    ‚úÖ Found PDF!")
                        break
                        
            except Exception as e:
                print(f"    ‚ùå Error testing {url}: {e}")
        
        return results

    def search_site_intelligently(self, site_config, tm_formats):
        """Generic intelligent site search based on configuration"""
        results = []
        site_name = site_config['name']
        
        print(f"üîç Searching {site_name} intelligently...")
        
        for method_config in site_config['methods']:
            method_type = method_config['type']
            
            if method_type == 'site_search_and_direct':
                # Try direct patterns first, then site search
                if 'direct_patterns' in method_config:
                    for pattern in method_config['direct_patterns']:
                        try:
                            url = pattern.format(**tm_formats)
                            print(f"  üîó Testing direct: {url}")
                            
                            response = self.session.head(url, timeout=8, allow_redirects=True)
                            if response.status_code == 200 and 'pdf' in response.headers.get('content-type', '').lower():
                                results.append({
                                    'url': url,
                                    'title': f"TM {tm_formats['tm_dashed']} - {site_name}",
                                    'confidence': 92,
                                    'method': 'direct_pdf',
                                    'site': site_name,
                                    'verified': True
                                })
                                print(f"    ‚úÖ Found direct PDF!")
                                return results
                        except Exception as e:
                            print(f"    ‚ùå Direct test failed: {e}")
                
                # If direct didn't work, try site search
                if 'search_url' in method_config:
                    query = f"TM {tm_formats['tm_dashed']}"
                    search_url = method_config['search_url'].format(query=urllib.parse.quote(query))
                    
                    try:
                        print(f"  üîç Site search: {search_url}")
                        response = self.session.get(search_url, timeout=15)
                        if response.status_code == 200:
                            soup = BeautifulSoup(response.text, 'html.parser')
                            
                            # Look for PDF links
                            for link in soup.find_all('a', href=True):
                                href = link.get('href', '')
                                text = link.get_text().lower()
                                
                                if ('.pdf' in href.lower() and 
                                    ('tm' in text or 'tm' in href.lower()) and
                                    any(part in href.lower() for part in tm_formats['tm_dashed'].split('-'))):
                                    
                                    if not href.startswith('http'):
                                        domain = site_config['domain']
                                        href = f"https://{domain}{href}" if href.startswith('/') else f"https://{domain}/{href}"
                                    
                                    results.append({
                                        'url': href,
                                        'title': f"TM {tm_formats['tm_dashed']} - {site_name}",
                                        'confidence': 85,
                                        'method': 'site_search',
                                        'site': site_name,
                                        'verified': False
                                    })
                                    print(f"    ‚úÖ Found via site search: {href}")
                                    return results
                    
                    except Exception as e:
                        print(f"    ‚ùå Site search error: {e}")
            
            elif method_type == 'site_search_only':
                # Special handling for RadioNerds - use hybrid method
                if site_name == 'Radio Nerds':
                    return self.search_radio_nerds_hybrid(tm_formats)
                
                # For other sites with this method type
                query = f"TM {tm_formats['tm_dashed']}"
                search_url = method_config['search_url'].format(query=urllib.parse.quote(query))
                
                try:
                    print(f"  üîç Site-only search: {search_url}")
                    response = self.session.get(search_url, timeout=15)
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.text, 'html.parser')
                        
                        # Look for PDF links in search results
                        for link in soup.find_all('a', href=True):
                            href = link.get('href', '')
                            text = link.get_text().lower()
                            
                            if ('.pdf' in href.lower() and 
                                ('tm' in text or 'tm' in href.lower()) and
                                any(part in href.lower() for part in tm_formats['tm_dashed'].split('-'))):
                                
                                if href.startswith('/'):
                                    href = f"https://{site_config['domain']}{href}"
                                elif not href.startswith('http'):
                                    href = f"https://{site_config['domain']}/{href}"
                                
                                # Verify PDF exists
                                try:
                                    head_response = self.session.head(href, timeout=5)
                                    if head_response.status_code == 200:
                                        results.append({
                                            'url': href,
                                            'title': f"TM {tm_formats['tm_dashed']} - {site_name}",
                                            'confidence': 88,
                                            'method': 'site_search',
                                            'site': site_name,
                                            'verified': True
                                        })
                                        print(f"    ‚úÖ Found and verified: {href}")
                                        return results
                                except:
                                    continue
                
                except Exception as e:
                    print(f"    ‚ùå Site search error: {e}")
                
                # Fallback to Google site search
                if 'fallback_google' in method_config:
                    google_query = method_config['fallback_google'].format(query=f"TM {tm_formats['tm_dashed']}")
                    google_url = f"https://www.google.com/search?q={urllib.parse.quote(google_query)}"
                    
                    results.append({
                        'url': google_url,
                        'title': f"Google search: TM {tm_formats['tm_dashed']} on {site_name}",
                        'confidence': 75,
                        'method': 'google_site_search',
                        'site': f"{site_name} (via Google)",
                        'verified': False,
                        'description': f'Manual search required: Click to search Google'
                    })
                    print(f"    ‚ÜóÔ∏è Added Google fallback")
            
            elif method_type == 'google_site_search':
                # Pure Google site search (for sites with poor search)
                if 'fallback_google' in method_config:
                    google_query = method_config['fallback_google'].format(query=f"TM {tm_formats['tm_dashed']}")
                    google_url = f"https://www.google.com/search?q={urllib.parse.quote(google_query)}"
                    
                    results.append({
                        'url': google_url,
                        'title': f"Google search: TM {tm_formats['tm_dashed']} on {site_name}",
                        'confidence': 70,
                        'method': 'google_site_search',
                        'site': f"{site_name} (via Google)",
                        'verified': False,
                        'description': f'Manual search required: Click to search Google'
                    })
                    print(f"    ‚ÜóÔ∏è Added Google site search")
        
        return results
    
    def search_tm_number(self, tm_number, max_results=5, use_partial_match=True):
        """Enhanced TM search with intelligent site searching"""
        print(f"\nüéØ Enhanced TM search for: {tm_number}")
        
        if not tm_number:
            return []
        
        tm_formats = self.format_tm_number(tm_number)
        all_results = []
        sorted_sites = sorted(self.target_sites, key=lambda x: x['priority'])
        
        # Search each site intelligently
        for site_config in sorted_sites:
            if len(all_results) >= max_results:
                break
            
            # Â¶ÇÊûúÂ∑≤ÁªèÊâæÂà∞verifiedÁªìÊûúÔºå‰∏îÂΩìÂâçÊòØRadioNerdsÔºåË∑≥Ëøá
            if (site_config['name'] == 'Radio Nerds' and 
                len(all_results) > 0):
                print(f"  ‚è≠Ô∏è Skipping RadioNerds - already found {len(all_results)} verified result(s)")
                continue
            
            try:
                site_results = self.search_site_intelligently(site_config, tm_formats)
                all_results.extend(site_results)
                
                if site_results:
                    print(f"  ‚úÖ {site_config['name']}: Found {len(site_results)} result(s)")
                    # If we found a verified PDF, we can stop searching other sites
                    if any(r.get('verified', False) for r in site_results):
                        break
                else:
                    print(f"  ‚ùå {site_config['name']}: No results")
                
            except Exception as e:
                print(f"  ‚ùå {site_config['name']} error: {e}")
        
        # Sort by confidence and verification status
        all_results.sort(key=lambda x: (x.get('verified', False), x.get('confidence', 0)), reverse=True)
        
        print(f"\nüìä Enhanced search complete: {len(all_results)} total results")
        return all_results[:max_results]

    def search_model_number(self, model_number, max_results=5):
        """Â¢ûÂº∫ÁöÑÊ®°ÂûãÂè∑ÊêúÁ¥¢ - ÂåÖÂê´Êò†Â∞ÑÊêúÁ¥¢"""
        print(f"\nüîç Enhanced model search for: {model_number}")
        
        if not model_number:
            return []
        
        all_results = []
        
        # 1. È¶ñÂÖàÂ∞ùËØïÊò†Â∞ÑÊêúÁ¥¢
        print("üéØ Step 1: Trying model-to-TM mapping...")
        tm_numbers = self.model_mapper.find_tm_numbers_for_model(model_number)
        
        if tm_numbers:
            print(f"   ‚úÖ Found TM mappings: {tm_numbers}")
            
            # ‰∏∫ÊØè‰∏™Êò†Â∞ÑÁöÑTMÂè∑ÊâßË°åÊêúÁ¥¢
            for tm_number in tm_numbers:
                print(f"   üéØ Searching for mapped TM: {tm_number}")
                
                try:
                    # ‰ΩøÁî®ÈÉ®ÂàÜÂåπÈÖçÂäüËÉΩÊêúÁ¥¢
                    tm_results = self.search_tm_number(tm_number, max_results=3, use_partial_match=True)
                    
                    # ‰∏∫ÁªìÊûúÊ∑ªÂä†Êò†Â∞Ñ‰ø°ÊÅØ
                    for result in tm_results:
                        result['title'] = f"{result['title']} (Mapped from {model_number})"
                        result['description'] = f"Found via model mapping: {model_number} ‚Üí TM {tm_number}"
                        result['method'] = 'model_to_tm_mapping'
                        result['mapped_from'] = model_number
                        result['mapped_tm'] = tm_number
                    
                    all_results.extend(tm_results)
                    
                    if tm_results:
                        print(f"     ‚úÖ Found {len(tm_results)} results for TM {tm_number}")
                        break  # ÊâæÂà∞Á¨¨‰∏Ä‰∏™ÊúâÁªìÊûúÁöÑTMÂêéÂÅúÊ≠¢
                    else:
                        print(f"     ‚ùå No results for TM {tm_number}")
                        
                except Exception as e:
                    print(f"     ‚ùå Error searching TM {tm_number}: {e}")
            
            if all_results:
                return all_results[:max_results]
        else:
            print(f"   ‚ùå No TM mappings found for {model_number}")
        
        # 2. Â¶ÇÊûúÊò†Â∞ÑÊêúÁ¥¢Ê≤°ÊúâÁªìÊûúÔºå‰ΩøÁî®‰º†ÁªüÊêúÁ¥¢
        print("üîÑ Step 2: Trying direct model search...")
        
        clean_model = model_number.upper().strip()
        model_variations = [
            clean_model,
            clean_model.replace('-', ''),
            clean_model.replace(' ', ''),
            clean_model.replace('/', '-'),
            f"MEP-{clean_model}" if not clean_model.startswith('MEP') else clean_model
        ]
        
        print(f"üìã Model variations: {model_variations}")
        
        try:
            print("üìö Searching Liberated Manuals for model...")
            for model_var in model_variations:
                search_url = f"https://www.liberatedmanuals.com/search?q={urllib.parse.quote(model_var)}"
                print(f"  üîç Searching: {search_url}")
                
                response = self.session.get(search_url, timeout=15)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    pdf_links = soup.find_all('a', href=re.compile(r'\.pdf$', re.I))
                    
                    for link in pdf_links:
                        href = link.get('href')
                        text = link.get_text().lower()
                        
                        if href and any(var.lower() in href.lower() or var.lower() in text for var in model_variations):
                            if not href.startswith('http'):
                                href = f"https://www.liberatedmanuals.com{href}"
                            
                            all_results.append({
                                'url': href,
                                'title': f"Manual for {model_number} - Liberated Manuals",
                                'confidence': 80,
                                'method': 'model_search',
                                'site': 'Liberated Manuals',
                                'verified': False
                            })
                            print(f"    ‚úÖ Found: {href}")
                            break
                
                if all_results:
                    break
                    
        except Exception as e:
            print(f"    ‚ùå Liberated Manuals model search error: {e}")
        
        print(f"üìä Enhanced model search complete: {len(all_results)} total results")
        return all_results[:max_results]

# ÂàõÂª∫ÊêúÁ¥¢Âô®ÂÆû‰æã
searcher = RealisticManualSearcher()

def search_manual_pdfs_realistic(tm_number=None, model_number=None):
    """‰∏ªÊêúÁ¥¢Êé•Âè£ - TM‰ºòÂÖàÔºàÊîØÊåÅÈÉ®ÂàÜÂåπÈÖçÔºâÔºåModelÂ§áÁî®"""
    all_results = []
    
    if tm_number:
        print(f"üéØ Priority search: TM {tm_number} (with partial matching)")
        # ÂêØÁî®ÈÉ®ÂàÜÂåπÈÖçÂäüËÉΩ
        tm_results = searcher.search_tm_number(tm_number, max_results=5, use_partial_match=True)
        all_results.extend(tm_results)
        
        if tm_results:
            print(f"‚úÖ TM search successful: {len(tm_results)} results")
            return all_results
    
    if not all_results and model_number:
        print(f"üîÑ Enhanced model search: {model_number}")
        model_results = searcher.search_model_number(model_number, max_results=5)
        all_results.extend(model_results)
    
    if not all_results:
        manual_search_query = tm_number if tm_number else model_number
        return [{
            'title': f'Manual Search: {manual_search_query}',
            'url': f"https://www.google.com/search?q={urllib.parse.quote(f'{manual_search_query} filetype:pdf')}",
            'description': f'No PDFs found in targeted databases. Click to search Google manually for "{manual_search_query}" PDF files.',
            'confidence': 50,
            'site': 'Google Manual Search',
            'method': 'manual_fallback',
            'verified': False
        }]
    
    return all_results

# OCR Áõ∏ÂÖ≥ÂáΩÊï∞
def extract_model_tm(text):
    """ÊèêÂèñMODELÂíåTMÂ≠óÊÆµ"""
    if not text:
        return {"model": None, "tm": None}
    
    result = {"model": None, "tm": None}
    text_upper = text.upper()
    
    # TMÂè∑ÂåπÈÖçÊ®°Âºè - ÊîØÊåÅ4ÊÆµÂíå5ÊÆµTMÂè∑
    tm_patterns = [
        r'TM[:\s]*(\d+-\d+-\d+-\d+[A-Z]*)',  # ÊîØÊåÅÂ¶Ç 9-6115-585-24P
        r'TM[:\s]*(\d+-\d+-\d+-\d+)',         # Ê†áÂáÜ4ÊÆµ
        r'\b(\d+-\d+-\d+-\d+[A-Z]*)\b',       # Êó†TMÂâçÁºÄ
        r'TM[:\s]*(\d+-\d+-\d+-\d+-\d+)',     # 5ÊÆµÊï∞Â≠óÊ†ºÂºè
    ]
    
    for pattern in tm_patterns:
        matches = re.findall(pattern, text_upper)
        for match in matches:
            clean_match = match.strip()
            if len(clean_match) >= 8 and re.match(r'\d+-\d+-\d+-', clean_match):
                result['tm'] = clean_match
                break
        if result['tm']:
            break
    
    # Ê®°ÂûãÂè∑ÂåπÈÖçÊ®°Âºè
    model_patterns = [
        r'\b(MEP[-\s]*[0-9]+[A-Z]*)\b',
        r'MODEL[:\s]*([A-Z0-9\-/]+)',
        r'\b(M[0-9]+[A-Z]*/?[A-Z]*)\b',
        r'\b([A-Z]{2,4}[-]?[0-9]{2,5}[A-Z]*/?[A-Z]*)\b'
    ]
    
    for pattern in model_patterns:
        matches = re.findall(pattern, text_upper)
        for match in matches:
            clean_match = re.sub(r'\s+', '', match.strip())
            
            exclude_patterns = [
                r'^TM\b', r'^TO\b', r'^\d+-\d+-\d+-',
                r'^120\b|^208\b|^240\b|^480\b'
            ]
            
            exclude_words = [
                'US', 'NATO', 'DEPARTMENT', 'GENERATOR', 'ENGINE', 'DIESEL',
                'POWER', 'ARMY', 'SYSTEM'
            ]
            
            should_exclude = (
                any(re.match(exclude_pattern, clean_match) for exclude_pattern in exclude_patterns) or
                any(word in clean_match for word in exclude_words) or
                len(clean_match) < 2 or clean_match.isdigit()
            )
            
            if not should_exclude:
                result['model'] = clean_match
                break
        if result['model']:
            break
    
    return result

def azure_ocr_with_layout(image_path):
    """Azure OCRÂ§ÑÁêÜ"""
    api_key = os.getenv('AZURE_VISION_KEY')
    endpoint = os.getenv('AZURE_VISION_ENDPOINT')
    
    if not api_key or not endpoint:
        return {
            "success": False, 
            "error": "ËØ∑ËÆæÁΩÆAZURE_VISION_KEYÂíåAZURE_VISION_ENDPOINTÁéØÂ¢ÉÂèòÈáè"
        }
    
    try:
        headers = {
            'Ocp-Apim-Subscription-Key': api_key,
            'Content-Type': 'application/octet-stream'
        }
        
        with open(image_path, 'rb') as image_file:
            image_data = image_file.read()
        
        url = f"{endpoint}/vision/v3.2/read/analyze"
        response = requests.post(url, headers=headers, data=image_data, timeout=30)
        
        if response.status_code == 202:
            operation_url = response.headers["Operation-Location"]
            
            while True:
                time.sleep(1)
                result_response = requests.get(
                    operation_url, 
                    headers={'Ocp-Apim-Subscription-Key': api_key},
                    timeout=30
                )
                
                if result_response.status_code == 200:
                    result = result_response.json()
                    if result["status"] == "succeeded":
                        text_lines = []
                        for read_result in result.get("analyzeResult", {}).get("readResults", []):
                            for line in read_result.get("lines", []):
                                text_lines.append(line["text"])
                        
                        if text_lines:
                            return {
                                "success": True,
                                "text": '\n'.join(text_lines),
                                "engine": "Azure Computer Vision Read API"
                            }
                        else:
                            return {"success": False, "error": "Êú™Ê£ÄÊµãÂà∞ÊñáÂ≠ó"}
                    elif result["status"] == "failed":
                        return {"success": False, "error": "Azure Read APIÂ§ÑÁêÜÂ§±Ë¥•"}
        else:
            return {
                "success": False, 
                "error": f"Azure APIÈîôËØØ: {response.status_code} - {response.text}"
            }
            
    except Exception as e:
        return {"success": False, "error": f"ËØ∑Ê±ÇÂ§±Ë¥•: {str(e)}"}

# Flask Ë∑ØÁî±
@app.route('/health', methods=['GET'])
def health():
    """ÂÅ•Â∫∑Ê£ÄÊü•"""
    return jsonify({
        "status": "ok",
        "service": "Enhanced Manual Search System with Partial TM Matching",
        "features": {
            "partial_tm_matching": True,
            "model_to_tm_mapping": True,
            "five_segment_tm_support": True,
            "green_mountain_direct_pdf": True
        },
        "target_sites": [site['name'] for site in searcher.target_sites],
        "search_strategy": "TM priority with partial matching, enhanced Model backup",
        "model_mappings": len(searcher.model_mapper.all_mappings),
    })

@app.route('/extract', methods=['POST'])
def extract():
    """ÊèêÂèñÈì≠Áâå‰ø°ÊÅØ"""
    try:
        print(f"[{time.strftime('%H:%M:%S')}] ÂºÄÂßãAzure OCRÂ§ÑÁêÜ")
        start_time = time.time()
        
        if 'file' not in request.files:
            return jsonify({"error": "ËØ∑‰∏ä‰º†ÂõæÁâáÊñá‰ª∂"}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({"error": "ËØ∑ÈÄâÊã©ÂõæÁâáÊñá‰ª∂"}), 400
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:
            file.save(temp_file.name)
            temp_path = temp_file.name
        
        print(f"Â§ÑÁêÜÊñá‰ª∂: {file.filename}")
        
        ocr_result = azure_ocr_with_layout(temp_path)
        
        try:
            os.unlink(temp_path)
        except:
            pass
        
        if ocr_result["success"]:
            fields = extract_model_tm(ocr_result["text"])
            total_time = time.time() - start_time
            
            result_data = {
                "model": fields["model"],
                "tm": fields["tm"],
                "found": bool(fields["model"] or fields["tm"]),
                "ocr_text": ocr_result["text"],
                "engine": "Azure Computer Vision",
                "processing_time": round(total_time, 2)
            }
            
            print(f"‚úÖ ÊàêÂäü: Model={fields['model']}, TM={fields['tm']}, ËÄóÊó∂={total_time:.2f}s")
            return jsonify(result_data)
        else:
            return jsonify({
                "error": ocr_result["error"],
                "model": None,
                "tm": None,
                "found": False
            }), 500
            
    except Exception as e:
        print(f"‚ùå ÈîôËØØ: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/search', methods=['POST'])
def search_manuals():
    """Âü∫‰∫éÁúüÂÆûURLÊ®°ÂºèÁöÑÁ≤æÂáÜÊêúÁ¥¢ - TM‰ºòÂÖàÁ≠ñÁï•ÔºåÂ¢ûÂº∫Ê®°ÂûãÊò†Â∞Ñ"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "No JSON data provided"}), 400
        
        tm_number = data.get('tm', '').strip() if data.get('tm') else None
        model_number = data.get('model', '').strip() if data.get('model') else None
        
        if not tm_number and not model_number:
            return jsonify({"error": "Please provide TM number or model number"}), 400
        
        print(f"üéØ Enhanced search request - TM: {tm_number}, Model: {model_number}")
        
        # Á°ÆÂÆöÊêúÁ¥¢Á≠ñÁï•
        if tm_number and model_number:
            search_strategy = "TM priority with partial matching and model backup"
        elif tm_number:
            search_strategy = "TM only with partial matching"
        else:
            search_strategy = "Enhanced model search with mapping"
        
        print(f"üìã Search strategy: {search_strategy}")
        
        # ‰ΩøÁî®Â¢ûÂº∫ÁöÑÊêúÁ¥¢Á≥ªÁªü
        results = search_manual_pdfs_realistic(tm_number, model_number)
        
        # ËΩ¨Êç¢ÁªìÊûúÊ†ºÂºè‰ª•ÂåπÈÖçÂâçÁ´ØÊúüÊúõ
        formatted_results = []
        for result in results:
            formatted_result = {
                'title': result.get('title', f"Manual for {tm_number or model_number}"),
                'url': result['url'],
                'description': result.get('description', f"Found via {result.get('site', 'search')} using {result.get('method', 'direct_pdf')} method"),
                'confidence': result.get('confidence', 80),
                'source': result.get('site', 'Enhanced Search'),
                'verified': result.get('verified', True),
                'method': result.get('method', 'enhanced_search')
            }
            
            # Ê∑ªÂä†ÈÉ®ÂàÜÂåπÈÖç‰ø°ÊÅØ
            if result.get('partial_match'):
                formatted_result['partial_match'] = True
                formatted_result['original_query'] = result.get('original_query')
                formatted_result['matched_tm'] = result.get('matched_tm')
            
            # Ê∑ªÂä†Êò†Â∞Ñ‰ø°ÊÅØÂà∞ÊèèËø∞‰∏≠
            if result.get('mapped_tm'):
                formatted_result['description'] += f" (Model {result.get('mapped_from')} ‚Üí TM {result.get('mapped_tm')})"
            
            formatted_results.append(formatted_result)
        
        return jsonify({
            "success": True,
            "query": {
                "tm": tm_number,
                "model": model_number,
                "strategy": search_strategy
            },
            "results": formatted_results,
            "total": len(formatted_results),
            "search_method": "enhanced_partial_matching_search"
        })
        
    except Exception as e:
        error_message = str(e)
        print(f"‚ùå Search error: {error_message}")
        
        return jsonify({
            "success": False,
            "error": error_message,
            "query": {
                "tm": tm_number if 'tm_number' in locals() else None,
                "model": model_number if 'model_number' in locals() else None
            },
            "results": [],
            "total": 0
        }), 500

@app.route('/search-stream-fixed', methods=['POST'])
def search_stream_fixed():
    """‰øÆÂ§çÁöÑÂÆûÊó∂ÊµÅÂºèÊêúÁ¥¢ - ÊîØÊåÅÈÉ®ÂàÜÂåπÈÖç"""
    try:
        data = request.get_json()
        tm_number = data.get('tm', '').strip() if data.get('tm') else None
        model_number = data.get('model', '').strip() if data.get('model') else None
        
        print(f"üéØ Fixed stream search - TM: {tm_number}, Model: {model_number}")
        
        def generate():
            import json
            result_count = 0
            all_results = []
            
            def send_data(msg_type, data=None, message=None):
                nonlocal result_count
                msg = {'type': msg_type}
                if message:
                    msg['message'] = message
                if data:
                    msg['data'] = data
                if msg_type == 'result':
                    msg['index'] = result_count
                    result_count += 1
                
                json_str = json.dumps(msg)
                print(f"üì§ Sending: {json_str}")
                return f"data: {json_str}\n\n"
            
            # ÂÆö‰πâÊêúÁ¥¢ÊñπÊ≥ï
            search_methods = [
                ('Liberated Manuals', searcher.search_liberated_manuals),
                ('Green Mountain', searcher.search_green_mountain),
                ('Combat Index', searcher.search_combat_index),
                ('Radio Nerds', searcher.search_radio_nerds)
            ]
            
            try:
                # ÂèëÈÄÅÂºÄÂßã‰ø°Âè∑
                yield send_data('start', message='Search started with partial matching support')
                
                # TMÊêúÁ¥¢ÔºàÊîØÊåÅÈÉ®ÂàÜÂåπÈÖçÔºâ
                if tm_number:
                    yield send_data('status', message=f'Starting TM search: {tm_number}')
                    
                    tm_formats = searcher.format_tm_number(tm_number)
                    found_exact = False
                    
                    # È¶ñÂÖàÂ∞ùËØïÁ≤æÁ°ÆÂåπÈÖç
                    for site_name, search_method in search_methods:
                        if site_name =='Radio Nerds' and len(all_results) > 0:
                            yield send_data('status', message=f'Skipping RadioNerds - already found{len(all_results)} result(s)')
                            continue
                        
                        yield send_data('status', message=f'Searching {site_name} for exact match...')
                        
                        try:
                            print(f"üîç Searching {site_name} for exact TM...")
                            site_results = search_method(tm_formats)
                            print(f"üìä {site_name} returned {len(site_results)} results")
                            
                            if site_results:
                                found_exact = True
                                for result in site_results:
                                    formatted_result = {
                                        'title': result.get('title', f'Manual from {site_name}'),
                                        'url': result['url'],
                                        'description': result.get('description', f'Found on {site_name}'),
                                        'confidence': result.get('confidence', 90),
                                        'source': result.get('site', site_name),
                                        'verified': result.get('verified', True),
                                        'isPdfResult': result.get('method', '') != 'manual_fallback',
                                        'title_suffix': result.get('title_suffix', '')
                                    }
                                    
                                    print(f"‚úÖ Sending result: {formatted_result['title']}")
                                    yield send_data('result', data=formatted_result)
                                    all_results.append(result)
                                
                                yield send_data('status', message=f'Found {len(site_results)} results on {site_name}')
                            else:
                                yield send_data('status', message=f'No exact match on {site_name}')
                                
                        except Exception as e:
                            error_msg = f'Error searching {site_name}: {str(e)}'
                            print(f"‚ùå {error_msg}")
                            yield send_data('status', message=error_msg)
                
                # Ê®°ÂûãÊêúÁ¥¢
                if not all_results and model_number:
                    yield send_data('status', message=f'Starting model search: {model_number}')
                    
                    # Ê£ÄÊü•Êò†Â∞Ñ
                    tm_numbers = searcher.model_mapper.find_tm_numbers_for_model(model_number)
                    
                    if tm_numbers:
                        yield send_data('status', message=f'Found mapping: {model_number} ‚Üí {tm_numbers}')
                        
                        # ÂØπÊØè‰∏™Êò†Â∞ÑÁöÑTMÂè∑ËøõË°åÊêúÁ¥¢ÔºàÂåÖÊã¨ÈÉ®ÂàÜÂåπÈÖçÔºâ
                        for tm_num in tm_numbers[:2]:  # ÊúÄÂ§öÊêúÁ¥¢Ââç2‰∏™TM
                            yield send_data('status', message=f'Searching mapped TM: {tm_num}')
                            
                            # ÈÄíÂΩíË∞ÉÁî®TMÊêúÁ¥¢Ôºà‰ºöËá™Âä®ÂåÖÂê´ÈÉ®ÂàÜÂåπÈÖçÔºâ
                            tm_results = searcher.search_tm_number(tm_num, max_results=3, use_partial_match=True)
                            
                            for result in tm_results:
                                result['title'] = f"{result['title']} (Mapped from {model_number})"
                                
                                formatted_result = {
                                    'title': result.get('title'),
                                    'url': result['url'],
                                    'description': f'Found via mapping: {model_number} ‚Üí TM {tm_num}',
                                    'confidence': result.get('confidence', 85),
                                    'source': result.get('site', 'Mapped Search'),
                                    'verified': result.get('verified', True),
                                    'isPdfResult': result.get('method', '') != 'manual_fallback'
                                }
                                
                                print(f"‚úÖ Sending mapped result: {formatted_result['title']}")
                                yield send_data('result', data=formatted_result)
                                all_results.append(result)
                            
                            if tm_results:
                                yield send_data('status', message=f'Found {len(tm_results)} mapped results')
                                break  # ÊâæÂà∞Â∞±ÂÅúÊ≠¢
                    else:
                        yield send_data('status', message=f'No mapping found for {model_number}, trying direct search...')
                        
                        # Áõ¥Êé•Ê®°ÂûãÊêúÁ¥¢‰Ωú‰∏∫Â§áÈÄâ
                        model_results = searcher.search_model_number(model_number, max_results=3)
                        
                        for result in model_results:
                            formatted_result = {
                                'title': result.get('title', f'Manual for {model_number}'),
                                'url': result['url'],
                                'description': result.get('description', f'Found via direct model search'),
                                'confidence': result.get('confidence', 75),
                                'source': result.get('site', 'Direct Search'),
                                'verified': result.get('verified', True),
                                'isPdfResult': result.get('method', '') != 'manual_fallback'
                            }
                            
                            yield send_data('result', data=formatted_result)
                            all_results.append(result)
                
                # ÂèëÈÄÅÂÆåÊàê‰ø°Âè∑
                print(f"üìä Final result count: {len(all_results)}")
                if all_results:
                    final_message = f'Search completed successfully - found {len(all_results)} manual(s)'
                    yield send_data('complete', message=final_message, data={'total': len(all_results), 'success': True})
                    print(f"‚úÖ {final_message}")
                else:
                    final_message = 'Search completed - no results found'
                    yield send_data('complete', message=final_message, data={'total': 0, 'success': False})
                    print(f"‚ö†Ô∏è {final_message}")
                    
            except Exception as e:
                error_msg = f'Search error: {str(e)}'
                print(f"‚ùå {error_msg}")
                yield send_data('error', message=error_msg)
        
        return app.response_class(
            generate(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'Content-Type'
            }
        )
        
    except Exception as e:
        print(f"‚ùå Stream endpoint error: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/test-tm/<tm_number>', methods=['GET'])
def test_tm_search(tm_number):
    """ÊµãËØïTMÊêúÁ¥¢ÂäüËÉΩ - Ë∞ÉËØïÁî®"""
    try:
        print(f"\nüß™ Testing TM search for: {tm_number}")
        
        # ÊµãËØïÊ†ºÂºèÂåñ
        tm_formats = searcher.format_tm_number(tm_number)
        print(f"üìã Formats generated: {tm_formats}")
        
        # ÊµãËØïÊØè‰∏™Á´ôÁÇπ
        site_results = {}
        
        # Liberated Manuals
        print("\nüìö Testing Liberated Manuals...")
        lib_results = searcher.search_liberated_manuals(tm_formats)
        site_results['liberated_manuals'] = lib_results
        
        # Radio Nerds
        print("\nüìª Testing Radio Nerds...")
        radio_results = searcher.search_radio_nerds(tm_formats)
        site_results['radio_nerds'] = radio_results
        
        # Green Mountain
        print("\nüîß Testing Green Mountain...")
        gm_results = searcher.search_green_mountain(tm_formats)
        site_results['green_mountain'] = gm_results
        
        # Combat Index
        print("\n‚öîÔ∏è Testing Combat Index...")
        combat_results = searcher.search_combat_index(tm_formats)
        site_results['combat_index'] = combat_results
        
        # ÂÆåÊï¥ÊêúÁ¥¢
        print("\nüéØ Running full search...")
        full_results = searcher.search_tm_number(tm_number, max_results=5, use_partial_match=False)
        
        return jsonify({
            'success': True,
            'tm_number': tm_number,
            'formats': tm_formats,
            'site_results': site_results,
            'full_search_results': full_results,
            'total_found': len(full_results)
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/list-mappings', methods=['GET'])
def list_mappings():
    """ÂàóÂá∫ÊâÄÊúâÊ®°ÂûãÂà∞TMÁöÑÊò†Â∞Ñ"""
    try:
        mapper = searcher.model_mapper
        
        return jsonify({
            'success': True,
            'total_mappings': len(mapper.all_mappings),
            'mappings': {
                'generators': mapper.generator_mappings,
                'communications': mapper.comm_mappings,
                'vehicles': mapper.vehicle_mappings
            },
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

if __name__ == '__main__':
    print("üéØ ÂêØÂä®Â¢ûÂº∫Êô∫ËÉΩÂÜõÁî®ÊâãÂÜåÊêúÁ¥¢Á≥ªÁªü - ÊîØÊåÅÈÉ®ÂàÜTMÂåπÈÖç")
    print("\nüìã Êñ∞ÂäüËÉΩÁâπÊÄß:")
    print("  ‚úÖ TMÂè∑ÈÉ®ÂàÜÂåπÈÖç: 9-6115-639-10 ‚Üí 9-6115-639-* ‚Üí 9-6115-639-13")
    print("  ‚úÖ ÊîØÊåÅ5ÊÆµTMÂè∑: 9-6115-585-24P")
    print("  ‚úÖ Green MountainÁõ¥Êé•PDFÈìæÊé•ÊîØÊåÅ")
    print("  ‚úÖ Êô∫ËÉΩÈôçÁ∫ßÊêúÁ¥¢Á≠ñÁï•")
    
    print("\nüåê APIÁ´ØÁÇπ:")
    print("  POST /extract - OCRÊèêÂèñÈì≠Áâå‰ø°ÊÅØ")
    print("  POST /search - Â¢ûÂº∫Êô∫ËÉΩÊêúÁ¥¢ÔºàÊîØÊåÅÈÉ®ÂàÜÂåπÈÖçÔºâ")
    print("  POST /search-stream-fixed - ÂÆûÊó∂ÊµÅÂºèÊêúÁ¥¢")
    print("  GET  /test-partial-match/<tm> - ÊµãËØïÈÉ®ÂàÜÂåπÈÖç")
    print("  GET  /list-mappings - ÂàóÂá∫ÊâÄÊúâÊò†Â∞Ñ")
    print("  GET  /health - Á≥ªÁªüÂÅ•Â∫∑Ê£ÄÊü•")
    
    print("\nüìä ÊêúÁ¥¢Á≠ñÁï•:")
    print("  1. TMÂè∑Á≤æÁ°ÆÂåπÈÖç ‚Üí Â§±Ë¥•ÂàôÂ∞ùËØïÂâç‰∏âÊÆµÈÉ®ÂàÜÂåπÈÖç")
    print("  2. ModelÊò†Â∞ÑÂà∞TM ‚Üí ÈÄíÂΩíÊâßË°åTMÊêúÁ¥¢ÔºàÂåÖÂê´ÈÉ®ÂàÜÂåπÈÖçÔºâ")
    print("  3. Áõ¥Êé•ModelÊêúÁ¥¢‰Ωú‰∏∫ÊúÄÂêéÂ§áÈÄâ")
    
    # ÊòæÁ§∫Êò†Â∞ÑÁªüËÆ°
    total_mappings = len(searcher.model_mapper.all_mappings)
    generators = len(searcher.model_mapper.generator_mappings)
    comms = len(searcher.model_mapper.comm_mappings)
    vehicles = len(searcher.model_mapper.vehicle_mappings)
    
    print(f"\nüìö Êï∞ÊçÆÂ∫ìÁªüËÆ°:")
    print(f"  üìà Ê®°ÂûãÊò†Â∞ÑÊÄªËÆ°: {total_mappings} ‰∏™")
    print(f"  üîã ÂèëÁîµÊú∫: {generators} ‰∏™")
    print(f"  üì° ÈÄö‰ø°ËÆæÂ§á: {comms} ‰∏™")
    print(f"  üöó ËΩ¶ËæÜ: {vehicles} ‰∏™")
    
    print(f"\nüí° ÈÉ®ÂàÜÂåπÈÖçÁ§∫‰æã:")
    print(f"  ËæìÂÖ•: 9-6115-639-10 (‰∏çÂ≠òÂú®)")
    print(f"  ÊêúÁ¥¢: 9-6115-639-*")
    print(f"  ÊâæÂà∞: 9-6115-639-13 ‚úÖ")
    
    print(f"\nüîó ÁõÆÊ†áÁΩëÁ´ô:")
    for i, site in enumerate(searcher.target_sites, 1):
        print(f"  {i}. {site['name']} - Priority {site['priority']}")
    
    # Ê£ÄÊü•AzureÈÖçÁΩÆ
    api_key = os.getenv('AZURE_VISION_KEY')
    endpoint = os.getenv('AZURE_VISION_ENDPOINT')
    
    if api_key and endpoint:
        print("\n‚úÖ Azure OCRÈÖçÁΩÆÂÆåÊàê")
        print(f"   Á´ØÁÇπ: {endpoint}")
        print(f"   ÂØÜÈí•: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '***'}")
    else:
        print("\n‚ö†Ô∏è Azure OCRÊú™ÈÖçÁΩÆÔºå‰ªÖÊêúÁ¥¢ÂäüËÉΩÂèØÁî®")
        print("   export AZURE_VISION_KEY='your-api-key'")
        print("   export AZURE_VISION_ENDPOINT='your-endpoint'")
    
    print("\nüåê ÊúçÂä°Âô®ÂêØÂä®Âú® http://127.0.0.1:3000")
    print("üìå ÂÆåÊï¥ÂäüËÉΩÂ∑≤ÂêØÁî®ÔºöÈÉ®ÂàÜÂåπÈÖç„ÄÅ5ÊÆµTM„ÄÅÁõ¥Êé•PDFÈìæÊé•")

    port = int(os.environ.get('PORT', 3000))
    app.run(host="0.0.0.0", port=port, debug=False)
